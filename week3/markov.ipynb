{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### N-Gram and Markov Chain\n",
    "To have a better understanding of n-gram, let's try to compose an n-gram manually in Python. For this purpose, we will take [a pangram](https://en.wikipedia.org/wiki/Pangram) as an example."
   ],
   "id": "b8ffd6b434e6a9d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:43:07.179658Z",
     "start_time": "2025-11-14T20:43:07.167049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pangram = \"The quick brown fox jumps over the lazy dog\"\n",
    "pangram_german = \"Franz jagt im komplett verwahrlosten Taxi quer durch Bayern\"\n",
    "\n",
    "def generate_ngram(text, n):\n",
    "    # n needs to be larger than 1\n",
    "    ngrams = []\n",
    "    words = text.split(\" \")\n",
    "    for i in range(len(words) - n + 1):\n",
    "        gram = words[i:i + n]\n",
    "        ngrams.append(gram)\n",
    "    return ngrams\n",
    "\n",
    "unigrams = pangram.split(\" \")\n",
    "print(\"Unigrams:\", unigrams)\n",
    "\n",
    "bigrams = generate_ngram(pangram, 2)\n",
    "print(\"Bigrams:\", bigrams)\n",
    "\n",
    "trigrams = generate_ngram(pangram, 3)\n",
    "print(\"Trigrams:\", trigrams)"
   ],
   "id": "8d5e455659cae0f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "Bigram: [['The', 'quick'], ['quick', 'brown'], ['brown', 'fox'], ['fox', 'jumps'], ['jumps', 'over'], ['over', 'the'], ['the', 'lazy'], ['lazy', 'dog']]\n",
      "Bigram: [['The', 'quick', 'brown'], ['quick', 'brown', 'fox'], ['brown', 'fox', 'jumps'], ['fox', 'jumps', 'over'], ['jumps', 'over', 'the'], ['over', 'the', 'lazy'], ['the', 'lazy', 'dog']]\n"
     ]
    }
   ],
   "execution_count": 317
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 1\n",
    "Try to modify the code above to generate bigram and trigram based on letters"
   ],
   "id": "6919f71921f6320c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T10:53:24.778796Z",
     "start_time": "2025-11-15T10:53:24.775110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_ngram_character(text, n):\n",
    "    # n needs to be larger than 1\n",
    "    pass\n",
    "\n",
    "unigrams = list(pangram)\n",
    "print(\"Unigram:\", unigrams)\n",
    "\n"
   ],
   "id": "86e63d7736279f65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram: ['T', 'h', 'e', ' ', 'q', 'u', 'i', 'c', 'k', ' ', 'b', 'r', 'o', 'w', 'n', ' ', 'f', 'o', 'x', ' ', 'j', 'u', 'm', 'p', 's', ' ', 'o', 'v', 'e', 'r', ' ', 't', 'h', 'e', ' ', 'l', 'a', 'z', 'y', ' ', 'd', 'o', 'g']\n",
      "Bigram: ['Th', 'he', 'e ', ' q', 'qu', 'ui', 'ic', 'ck', 'k ', ' b', 'br', 'ro', 'ow', 'wn', 'n ', ' f', 'fo', 'ox', 'x ', ' j', 'ju', 'um', 'mp', 'ps', 's ', ' o', 'ov', 've', 'er', 'r ', ' t', 'th', 'he', 'e ', ' l', 'la', 'az', 'zy', 'y ', ' d', 'do', 'og']\n",
      "Bigram: ['The', 'he ', 'e q', ' qu', 'qui', 'uic', 'ick', 'ck ', 'k b', ' br', 'bro', 'row', 'own', 'wn ', 'n f', ' fo', 'fox', 'ox ', 'x j', ' ju', 'jum', 'ump', 'mps', 'ps ', 's o', ' ov', 'ove', 'ver', 'er ', 'r t', ' th', 'the', 'he ', 'e l', ' la', 'laz', 'azy', 'zy ', 'y d', ' do', 'dog']\n"
     ]
    }
   ],
   "execution_count": 524
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "One can also use the nltk library to generate ngram. You can install the nltk library by running the cell below:",
   "id": "b80d2c8c5bdffe85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T16:41:48.934686Z",
     "start_time": "2025-11-13T16:41:47.743222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nltk"
   ],
   "id": "f423d7d740105fbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (3.9.2)\r\n",
      "Requirement already satisfied: click in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (from nltk) (8.3.0)\r\n",
      "Requirement already satisfied: joblib in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (from nltk) (1.5.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (from nltk) (2025.11.3)\r\n",
      "Requirement already satisfied: tqdm in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (from nltk) (4.67.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T16:43:48.680989Z",
     "start_time": "2025-11-13T16:43:48.677029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "# words\n",
    "bigrams = list(ngrams(pangram.split(\" \"), 2))\n",
    "trigrams = list(ngrams(pangram.split(\" \"), 3))\n",
    "\n",
    "print(\"Bigrams:\", bigrams)\n",
    "print(\"Trigrams:\", trigrams)\n",
    "\n",
    "# letters\n",
    "bigrams = list(ngrams(pangram, 2))\n",
    "trigrams = list(ngrams(pangram, 3))\n",
    "\n",
    "print(\"Bigrams:\", bigrams)\n",
    "print(\"Trigrams:\", trigrams)\n"
   ],
   "id": "c50a4224f77ff97f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams: [('The', 'quick'), ('quick', 'brown'), ('brown', 'fox'), ('fox', 'jumps'), ('jumps', 'over'), ('over', 'the'), ('the', 'lazy'), ('lazy', 'dog')]\n",
      "Trigrams: [('The', 'quick', 'brown'), ('quick', 'brown', 'fox'), ('brown', 'fox', 'jumps'), ('fox', 'jumps', 'over'), ('jumps', 'over', 'the'), ('over', 'the', 'lazy'), ('the', 'lazy', 'dog')]\n",
      "Bigrams: [('T', 'h'), ('h', 'e'), ('e', ' '), (' ', 'q'), ('q', 'u'), ('u', 'i'), ('i', 'c'), ('c', 'k'), ('k', ' '), (' ', 'b'), ('b', 'r'), ('r', 'o'), ('o', 'w'), ('w', 'n'), ('n', ' '), (' ', 'f'), ('f', 'o'), ('o', 'x'), ('x', ' '), (' ', 'j'), ('j', 'u'), ('u', 'm'), ('m', 'p'), ('p', 's'), ('s', ' '), (' ', 'o'), ('o', 'v'), ('v', 'e'), ('e', 'r'), ('r', ' '), (' ', 't'), ('t', 'h'), ('h', 'e'), ('e', ' '), (' ', 'l'), ('l', 'a'), ('a', 'z'), ('z', 'y'), ('y', ' '), (' ', 'd'), ('d', 'o'), ('o', 'g')]\n",
      "Trigrams: [('T', 'h', 'e'), ('h', 'e', ' '), ('e', ' ', 'q'), (' ', 'q', 'u'), ('q', 'u', 'i'), ('u', 'i', 'c'), ('i', 'c', 'k'), ('c', 'k', ' '), ('k', ' ', 'b'), (' ', 'b', 'r'), ('b', 'r', 'o'), ('r', 'o', 'w'), ('o', 'w', 'n'), ('w', 'n', ' '), ('n', ' ', 'f'), (' ', 'f', 'o'), ('f', 'o', 'x'), ('o', 'x', ' '), ('x', ' ', 'j'), (' ', 'j', 'u'), ('j', 'u', 'm'), ('u', 'm', 'p'), ('m', 'p', 's'), ('p', 's', ' '), ('s', ' ', 'o'), (' ', 'o', 'v'), ('o', 'v', 'e'), ('v', 'e', 'r'), ('e', 'r', ' '), ('r', ' ', 't'), (' ', 't', 'h'), ('t', 'h', 'e'), ('h', 'e', ' '), ('e', ' ', 'l'), (' ', 'l', 'a'), ('l', 'a', 'z'), ('a', 'z', 'y'), ('z', 'y', ' '), ('y', ' ', 'd'), (' ', 'd', 'o'), ('d', 'o', 'g')]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Text Generation with Markov Chain\n",
    "\n",
    "We will be using the Markovify library to play with Markov chain in Python."
   ],
   "id": "e6c46f878bf87be2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T10:56:35.463670Z",
     "start_time": "2025-11-15T10:56:34.339914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install markovify"
   ],
   "id": "4ab9084f0cbfa755",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markovify in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (0.9.4)\r\n",
      "Requirement already satisfied: unidecode in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (from markovify) (1.4.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 525
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After installation, import the library into the notebook.",
   "id": "8f53df3d0177d59c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T10:56:55.861321Z",
     "start_time": "2025-11-15T10:56:55.858337Z"
    }
   },
   "cell_type": "code",
   "source": "import markovify",
   "id": "f99e2bc18c11f0f6",
   "outputs": [],
   "execution_count": 526
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's try to create a markov chain with the same example sentence we had from the previous session, \"A rose is a rose is a rose\". Let's first specify the `state_size` parameter to 1 because the default value is 2. You can try to change the value to 2 and observe the change in the printed result.",
   "id": "44968b11c8384ef3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T11:03:57.194553Z",
     "start_time": "2025-11-15T11:03:57.190780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "text = \"A rose is a rose is a rose .\"\n",
    "# Build the model.\n",
    "text_model = markovify.Text(text, state_size=1)\n",
    "model_str = text_model.chain.to_json()\n",
    "model_json = json.loads(model_str)\n",
    "print(model_str)\n",
    "\n",
    "# notice that markovify always try to make sure to generate new sentence that is not present in the original data.\n",
    "for i in range(2):\n",
    "    print(text_model.make_sentence())\n"
   ],
   "id": "53813bb14d2d1857",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[\"___BEGIN__\"], {\"A\": 1}], [[\"A\"], {\"rose\": 1}], [[\"rose\"], {\"is\": 2, \".\": 1}], [[\"is\"], {\"a\": 2}], [[\"a\"], {\"rose\": 2}], [[\".\"], {\"___END__\": 1}]]\n",
      "A rose .\n",
      "A rose .\n"
     ]
    }
   ],
   "execution_count": 538
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can use the following code to generate a more readable output of the model.",
   "id": "f52bc31a0c681d03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T11:03:05.627762Z",
     "start_time": "2025-11-15T11:03:05.622945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_print(obj, indent=0):\n",
    "    space = \" \" * indent\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        print(space + \"{\")\n",
    "        for k, v in obj.items():\n",
    "            print(space + \"  \" + f\"{k}: \", end=\"\")\n",
    "            custom_print(v, indent + 2)\n",
    "        print(space + \"}\")\n",
    "\n",
    "    elif isinstance(obj, list):\n",
    "        print(\"[\", end=\"\")\n",
    "        for i, v in enumerate(obj):\n",
    "            if i > 0:\n",
    "                print(\", \", end=\"\")\n",
    "            custom_print(v, 0)\n",
    "        print(\"]\")\n",
    "\n",
    "    else:\n",
    "        # print primitives without quotes\n",
    "        print(obj, end=\"\")\n",
    "\n",
    "\n",
    "custom_print(model_json, indent=4)\n"
   ],
   "id": "f0bea54a953b1c22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[___BEGIN__, ___BEGIN__]\n",
      ", {\n",
      "  A: 1}\n",
      "]\n",
      ", [[___BEGIN__, A]\n",
      ", {\n",
      "  rose: 1}\n",
      "]\n",
      ", [[A, rose]\n",
      ", {\n",
      "  is: 1}\n",
      "]\n",
      ", [[rose, is]\n",
      ", {\n",
      "  a: 2}\n",
      "]\n",
      ", [[is, a]\n",
      ", {\n",
      "  rose: 2}\n",
      "]\n",
      ", [[a, rose]\n",
      ", {\n",
      "  is: 1  .: 1}\n",
      "]\n",
      ", [[rose, .]\n",
      ", {\n",
      "  ___END__: 1}\n",
      "]\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 534
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After having a good understanding of how Markovify works, let's try to feed the model with more data. In the week3 folder, you can find a txt file containing <i>The Picture of Dorian Gray</i> from Oscar Wilde, downloaded from Project Gutenberg.",
   "id": "773564aa4c2495e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T11:07:11.166833Z",
     "start_time": "2025-11-15T11:07:11.162012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get raw text as string.\n",
    "with open(\"pg26740.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "meta, sep, content = text.partition(\"THE PREFACE\") # using the .partition() method to get rid of text about the book\n",
    "print(meta)"
   ],
   "id": "ebe389efaee2c4e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg eBook of The Picture of Dorian Gray\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n",
      "Title: The Picture of Dorian Gray\n",
      "\n",
      "Author: Oscar Wilde\n",
      "\n",
      "Release date: October 1, 2008 [eBook #26740]\n",
      "                Most recently updated: March 10, 2010\n",
      "\n",
      "Language: English\n",
      "\n",
      "Credits: Produced by David Clarke, Chuck Greif and the Online\n",
      "        Distributed Proofreading Team at http://www.pgdp.net\n",
      "\n",
      "\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK THE PICTURE OF DORIAN GRAY ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by David Clarke, Chuck Greif and the Online\n",
      "Distributed Proofreading Team at http://www.pgdp.net\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE PICTURE OF DORIAN GRAY\n",
      "\n",
      "BY\n",
      "\n",
      "OSCAR WILDE\n",
      "\n",
      "LONDON: SIMPKIN, MARSHALL,\n",
      "\n",
      "HAMILTON, KENT & CO., LTD.\n",
      "\n",
      "PARIS\n",
      "\n",
      "ON SALE AT YE OLD PARIS BOOKE SHOPPE\n",
      "\n",
      "11 RUE DE CHÂTEAUDUN\n",
      "\n",
      "_Registered at Stationers' Hall and protected\n",
      "under the Copyright Law Act.\n",
      "\n",
      "First published in complete book form in 1891 by\n",
      "Messrs. Ward, Lock & Co. (London),\n",
      "\n",
      "First printed in this Edition April 1913,\n",
      "Reprinted June 1913, September 1913,\n",
      "June 1914, January 1916\n",
      "October 1916._\n",
      "\n",
      "_See the Bibliographical Note on certain Pirated and Mutilated\n",
      "Editions of \"Dorian Gray\" at the end of this present volume._\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 540
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T11:07:38.793078Z",
     "start_time": "2025-11-15T11:07:38.501023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build the model.\n",
    "text_model = markovify.Text(content)\n",
    "\n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    print(text_model.make_sentence())"
   ],
   "id": "2ecabec452e937eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you received the news of Sibyl Vane.\n",
      "He had been our ambassador at Madrid when Isabella was young, and catching the meaning of his exquisite youth and beauty.\n",
      "The poor chap was killed in a number of other people.\n",
      "He was not so abstruse as I was dominated, soul, brain, and the piano and let his fingers upon the latch.\n",
      "She was conscious of sharing with the idea, and grew louder.\n"
     ]
    }
   ],
   "execution_count": 541
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also specify the maximum character length for the generated sentence with `make_short_sentence()`.\n",
   "id": "c5f1fa69022627d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T11:10:09.405006Z",
     "start_time": "2025-11-15T11:10:09.342633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print three randomly-generated sentences of no more than 20 characters\n",
    "for i in range(3):\n",
    "    print(text_model.make_short_sentence(20, tries=100)) # increase attempt to reduce the chance of None for short sentences"
   ],
   "id": "37f1c66cb10912d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't look so good.\n",
      "I must go and look.\n",
      "As he was safe.\n"
     ]
    }
   ],
   "execution_count": 543
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can use this technique to create some rhythm in our generated result.",
   "id": "7aeeb1194db5295a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T11:12:07.054804Z",
     "start_time": "2025-11-15T11:12:07.025454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Self defined function to make sure a sentence is within a character range between min and max\n",
    "def make_sentence_range(min, max, tries=10):\n",
    "    # using a while loop here to avoid the case of None\n",
    "    sentence = None\n",
    "    for i in range(tries):\n",
    "        sentence = text_model.make_short_sentence(max)\n",
    "        if sentence is not None and len(sentence) > min:\n",
    "            break\n",
    "    return sentence\n",
    "\n",
    "print(text_model.make_short_sentence(30, tries=100))\n",
    "print(make_sentence_range(80, 100))\n",
    "print(text_model.make_short_sentence(20, tries=100))"
   ],
   "id": "3ee00b86dc80f0d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sense of humanity.\n",
      "Everything could be destroyed by the midnight train, and I have a spy in one's house.\n",
      "Credit is the type.\n"
     ]
    }
   ],
   "execution_count": 545
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Markovify assumes us to use text files with normal sentence punctuation by default. If your text file is using line breaks instead (poems, list of words, headlines...) you can use `markovify.NewlineText()` instead.",
   "id": "a87caebee65cf2b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T11:15:33.088950Z",
     "start_time": "2025-11-15T11:15:33.014593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = open(\"../week2/list.txt\").read()\n",
    "model = markovify.NewlineText(text, state_size=1)\n",
    "\n",
    "for i in range(3):\n",
    "    print(model.make_sentence(tries=100))\n"
   ],
   "id": "80c5f82373336885",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's a fire starting in my heart inside of your hand\n",
      "What is your view of the party and the morning seems so grey\n",
      "There's a fire starting in my heart inside of your hand\n",
      "But I don't know what\n"
     ]
    }
   ],
   "execution_count": 550
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Markovify uses word-level Markov chains by default, but we can modify its behavior to build character-level models instead. Character-level Markov models are especially useful for generating new words or names. In this example, we’ll use a list of color names to train a character-level model and generate new, Markovify-based color names.",
   "id": "6970e52eb903b180"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T11:18:34.556414Z",
     "start_time": "2025-11-15T11:18:34.550673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We are defining our own class here based on the NewlineText class from markovify\n",
    "class CharacterText(markovify.NewlineText):\n",
    "    # Split text into characters\n",
    "    def word_split(self, sentence):\n",
    "        return list(sentence)\n",
    "\n",
    "    # Join characters back into a string\n",
    "    def word_join(self, words):\n",
    "        return \"\".join(words)\n",
    "\n",
    "text = open(\"100_color_names.txt\").read()\n",
    "\n",
    "# Build the model.\n",
    "model = CharacterText(text, state_size=2)\n",
    "\n",
    "print(\"Generated color names:\")\n",
    "# Generate text\n",
    "for i in range(5):\n",
    "    print(model.make_sentence(tries=100))"
   ],
   "id": "bb97b55042e66b2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated color names:\n",
      "Peria\n",
      "Amberry\n",
      "Bricotta\n",
      "Rusty\n",
      "Zaffronze\n"
     ]
    }
   ],
   "execution_count": 552
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Combining wo markov models\n",
   "id": "7af8be4257555e79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can merge combine two different markov models and mix them in the ratio that you want.",
   "id": "567f17f1767da1e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:03:09.604737Z",
     "start_time": "2025-11-14T22:03:09.309849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model A loads Frankenstein\n",
    "with open(\"pg84.txt\") as f:\n",
    "    text_a = f.read()\n",
    "\n",
    "meta_a, sep_a, content_a = text_a.partition(\"Letter 1\")\n",
    "#print(meta_a)\n",
    "model_a = markovify.Text(content_a, state_size=3)\n",
    "\n",
    "# Model B loads Thus Spake Zarathustra\n",
    "with open(\"pg1998.txt\") as f:\n",
    "    text_b = f.read()\n",
    "\n",
    "meta_b, sep_b, content_b = text_b.partition(\"\\n\\nTHUS SPAKE ZARATHUSTRA.\\n\\n\")\n",
    "# print(meta_b)\n",
    "model_b = markovify.Text(content_b, state_size=3)\n",
    "\n",
    "model_combined = markovify.combine([ model_a, model_b ], [ 1, 1 ])  # merging them with the ratio of 1:1\n"
   ],
   "id": "7ad6764a4263a2b1",
   "outputs": [],
   "execution_count": 453
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can try to generate a paragraph with more consistency by using `make_sentence_with_start()`.",
   "id": "79e2bdbff1583c96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T11:21:26.309265Z",
     "start_time": "2025-11-15T11:21:26.293237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first = model_combined.make_sentence_with_start(\"I\", tries=100)\n",
    "second = model_combined.make_sentence_with_start(\"Zarathustra\", tries=100)\n",
    "third = model_combined.make_sentence_with_start(\"He\", tries=100)\n",
    "paragraph = first + \" \" + second + \" \" + third\n",
    "\n",
    "print(paragraph)"
   ],
   "id": "7e9e28603f3171b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I instantly wrote to Geneva; nearly two months after the death of my adversary. Zarathustra recognises another higher man in the moon than in the woman. He endeavoured to soothe me as a wretch doomed to ignominy and perdition.\n"
     ]
    }
   ],
   "execution_count": 553
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For more detailed documentation, check out [the official GitHub Repository](https://github.com/jsvine/markovify).",
   "id": "aa209dfd4e691c4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 2\n",
    "\n",
    "Find two text files of distinct styles and try to merge them with markovify."
   ],
   "id": "809733477afc4be5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dff24fa76ddf7138"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
