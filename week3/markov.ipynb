{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### N-Gram and Markov Chain\n",
    "To have a better understanding of n-gram, let's try to compose an n-gram manually in Python. For this purpose, we will take [a pangram](https://en.wikipedia.org/wiki/Pangram) as an example."
   ],
   "id": "b8ffd6b434e6a9d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:43:07.179658Z",
     "start_time": "2025-11-14T20:43:07.167049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pangram = \"The quick brown fox jumps over the lazy dog\"\n",
    "pangram_german = \"Franz jagt im komplett verwahrlosten Taxi quer durch Bayern\"\n",
    "\n",
    "def generate_ngram(text, n):\n",
    "    # n needs to be larger than 1\n",
    "    ngrams = []\n",
    "    words = text.split(\" \")\n",
    "    for i in range(len(words) - n + 1):\n",
    "        gram = words[i:i + n]\n",
    "        ngrams.append(gram)\n",
    "    return ngrams\n",
    "\n",
    "unigrams = pangram.split(\" \")\n",
    "print(\"Unigram:\", unigrams)\n",
    "\n",
    "bigrams = generate_ngram(pangram, 2)\n",
    "print(\"Bigram:\", bigrams)\n",
    "\n",
    "trigrams = generate_ngram(pangram, 3)\n",
    "print(\"Bigram:\", trigrams)"
   ],
   "id": "8d5e455659cae0f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "Bigram: [['The', 'quick'], ['quick', 'brown'], ['brown', 'fox'], ['fox', 'jumps'], ['jumps', 'over'], ['over', 'the'], ['the', 'lazy'], ['lazy', 'dog']]\n",
      "Bigram: [['The', 'quick', 'brown'], ['quick', 'brown', 'fox'], ['brown', 'fox', 'jumps'], ['fox', 'jumps', 'over'], ['jumps', 'over', 'the'], ['over', 'the', 'lazy'], ['the', 'lazy', 'dog']]\n"
     ]
    }
   ],
   "execution_count": 317
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 1\n",
    "Try to modify the code above to generate bigram and trigram based on letters"
   ],
   "id": "6919f71921f6320c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T16:37:54.748049Z",
     "start_time": "2025-11-13T16:37:54.745036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_ngram_character(text, n):\n",
    "    # n needs to be larger than 1\n",
    "    pass\n",
    "\n",
    "unigrams = list(pangram)\n",
    "print(\"Unigram:\", unigrams)\n",
    "\n"
   ],
   "id": "86e63d7736279f65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram: ['T', 'h', 'e', ' ', 'q', 'u', 'i', 'c', 'k', ' ', 'b', 'r', 'o', 'w', 'n', ' ', 'f', 'o', 'x', ' ', 'j', 'u', 'm', 'p', 's', ' ', 'o', 'v', 'e', 'r', ' ', 't', 'h', 'e', ' ', 'l', 'a', 'z', 'y', ' ', 'd', 'o', 'g']\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "One can also use the nltk library to generate ngram. You can install the nltk library by running the cell below:",
   "id": "b80d2c8c5bdffe85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T16:41:48.934686Z",
     "start_time": "2025-11-13T16:41:47.743222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nltk"
   ],
   "id": "f423d7d740105fbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (3.9.2)\r\n",
      "Requirement already satisfied: click in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (from nltk) (8.3.0)\r\n",
      "Requirement already satisfied: joblib in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (from nltk) (1.5.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (from nltk) (2025.11.3)\r\n",
      "Requirement already satisfied: tqdm in /Users/cqx931/projects/leuphana/2025_WS/AsWeMaySpeak/.venv/lib/python3.12/site-packages (from nltk) (4.67.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T16:43:48.680989Z",
     "start_time": "2025-11-13T16:43:48.677029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "# words\n",
    "bigrams = list(ngrams(pangram.split(\" \"), 2))\n",
    "trigrams = list(ngrams(pangram.split(\" \"), 3))\n",
    "\n",
    "print(\"Bigrams:\", bigrams)\n",
    "print(\"Trigrams:\", trigrams)\n",
    "\n",
    "# letters\n",
    "bigrams = list(ngrams(pangram, 2))\n",
    "trigrams = list(ngrams(pangram, 3))\n",
    "\n",
    "print(\"Bigrams:\", bigrams)\n",
    "print(\"Trigrams:\", trigrams)\n"
   ],
   "id": "c50a4224f77ff97f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams: [('The', 'quick'), ('quick', 'brown'), ('brown', 'fox'), ('fox', 'jumps'), ('jumps', 'over'), ('over', 'the'), ('the', 'lazy'), ('lazy', 'dog')]\n",
      "Trigrams: [('The', 'quick', 'brown'), ('quick', 'brown', 'fox'), ('brown', 'fox', 'jumps'), ('fox', 'jumps', 'over'), ('jumps', 'over', 'the'), ('over', 'the', 'lazy'), ('the', 'lazy', 'dog')]\n",
      "Bigrams: [('T', 'h'), ('h', 'e'), ('e', ' '), (' ', 'q'), ('q', 'u'), ('u', 'i'), ('i', 'c'), ('c', 'k'), ('k', ' '), (' ', 'b'), ('b', 'r'), ('r', 'o'), ('o', 'w'), ('w', 'n'), ('n', ' '), (' ', 'f'), ('f', 'o'), ('o', 'x'), ('x', ' '), (' ', 'j'), ('j', 'u'), ('u', 'm'), ('m', 'p'), ('p', 's'), ('s', ' '), (' ', 'o'), ('o', 'v'), ('v', 'e'), ('e', 'r'), ('r', ' '), (' ', 't'), ('t', 'h'), ('h', 'e'), ('e', ' '), (' ', 'l'), ('l', 'a'), ('a', 'z'), ('z', 'y'), ('y', ' '), (' ', 'd'), ('d', 'o'), ('o', 'g')]\n",
      "Trigrams: [('T', 'h', 'e'), ('h', 'e', ' '), ('e', ' ', 'q'), (' ', 'q', 'u'), ('q', 'u', 'i'), ('u', 'i', 'c'), ('i', 'c', 'k'), ('c', 'k', ' '), ('k', ' ', 'b'), (' ', 'b', 'r'), ('b', 'r', 'o'), ('r', 'o', 'w'), ('o', 'w', 'n'), ('w', 'n', ' '), ('n', ' ', 'f'), (' ', 'f', 'o'), ('f', 'o', 'x'), ('o', 'x', ' '), ('x', ' ', 'j'), (' ', 'j', 'u'), ('j', 'u', 'm'), ('u', 'm', 'p'), ('m', 'p', 's'), ('p', 's', ' '), ('s', ' ', 'o'), (' ', 'o', 'v'), ('o', 'v', 'e'), ('v', 'e', 'r'), ('e', 'r', ' '), ('r', ' ', 't'), (' ', 't', 'h'), ('t', 'h', 'e'), ('h', 'e', ' '), ('e', ' ', 'l'), (' ', 'l', 'a'), ('l', 'a', 'z'), ('a', 'z', 'y'), ('z', 'y', ' '), ('y', ' ', 'd'), (' ', 'd', 'o'), ('d', 'o', 'g')]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Text Generation with Markov Chain\n",
    "\n",
    "We will be using the Markovify library to play with Markov chain in Python."
   ],
   "id": "e6c46f878bf87be2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T16:49:23.313906Z",
     "start_time": "2025-11-13T16:49:21.637804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install markovify"
   ],
   "id": "4ab9084f0cbfa755",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markovify\r\n",
      "  Obtaining dependency information for markovify from https://files.pythonhosted.org/packages/89/6c/daf4527ea22e9c9c7c7638c9b60a61b45f0a9b9aa181b512137b98fd83f1/markovify-0.9.4-py3-none-any.whl.metadata\r\n",
      "  Downloading markovify-0.9.4-py3-none-any.whl.metadata (23 kB)\r\n",
      "Collecting unidecode (from markovify)\r\n",
      "  Obtaining dependency information for unidecode from https://files.pythonhosted.org/packages/8f/b7/559f59d57d18b44c6d1250d2eeaa676e028b9c527431f5d0736478a73ba1/Unidecode-1.4.0-py3-none-any.whl.metadata\r\n",
      "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Using cached markovify-0.9.4-py3-none-any.whl (19 kB)\r\n",
      "Using cached Unidecode-1.4.0-py3-none-any.whl (235 kB)\r\n",
      "Installing collected packages: unidecode, markovify\r\n",
      "Successfully installed markovify-0.9.4 unidecode-1.4.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After installation, import the library into the notebook.",
   "id": "8f53df3d0177d59c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T16:50:58.516807Z",
     "start_time": "2025-11-13T16:50:58.504966Z"
    }
   },
   "cell_type": "code",
   "source": "import markovify",
   "id": "f99e2bc18c11f0f6",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's try to create a markov chain with the same example sentence we had from the previous session, \"A rose is a rose is a rose\". Let's first specify the `state_size` parameter to 1 because the default value is 2. You can try to change the value to 2 and observe the change in the printed result.",
   "id": "44968b11c8384ef3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T19:38:22.823194Z",
     "start_time": "2025-11-14T19:38:22.817816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "text = \"A rose is a rose is a rose .\"\n",
    "# Build the model.\n",
    "text_model = markovify.Text(text, state_size=1)\n",
    "model_str = text_model.chain.to_json()\n",
    "model_json = json.loads(model_str)\n",
    "print(model_str)\n",
    "\n",
    "# notice that markovify always try to make sure to generate new sentence that is not present in the original data.\n",
    "for i in range(2):\n",
    "    print(text_model.make_sentence())\n"
   ],
   "id": "53813bb14d2d1857",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[\"___BEGIN__\"], {\"A\": 1}], [[\"A\"], {\"rose\": 1}], [[\"rose\"], {\"is\": 2, \".\": 1}], [[\"is\"], {\"a\": 2}], [[\"a\"], {\"rose\": 2}], [[\".\"], {\"___END__\": 1}]]\n",
      "A rose is a rose is a rose is a rose is a rose .\n",
      "A rose is a rose is a rose is a rose is a rose is a rose is a rose is a rose is a rose is a rose is a rose .\n"
     ]
    }
   ],
   "execution_count": 233
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can use the following code to generate a more readable output of the model.",
   "id": "f52bc31a0c681d03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T19:38:12.048051Z",
     "start_time": "2025-11-14T19:38:12.043721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_print(obj, indent=0):\n",
    "    space = \" \" * indent\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        print(space + \"{\")\n",
    "        for k, v in obj.items():\n",
    "            print(space + \"  \" + f\"{k}: \", end=\"\")\n",
    "            custom_print(v, indent + 2)\n",
    "        print(space + \"}\")\n",
    "\n",
    "    elif isinstance(obj, list):\n",
    "        print(\"[\", end=\"\")\n",
    "        for i, v in enumerate(obj):\n",
    "            if i > 0:\n",
    "                print(\", \", end=\"\")\n",
    "            custom_print(v, 0)\n",
    "        print(\"]\")\n",
    "\n",
    "    else:\n",
    "        # print primitives without quotes\n",
    "        print(obj, end=\"\")\n",
    "\n",
    "\n",
    "custom_print(model_json, indent=4)\n"
   ],
   "id": "f0bea54a953b1c22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[___BEGIN__, ___BEGIN__]\n",
      ", {\n",
      "  A: 1}\n",
      "]\n",
      ", [[___BEGIN__, A]\n",
      ", {\n",
      "  rose: 1}\n",
      "]\n",
      ", [[A, rose]\n",
      ", {\n",
      "  is: 1}\n",
      "]\n",
      ", [[rose, is]\n",
      ", {\n",
      "  a: 2}\n",
      "]\n",
      ", [[is, a]\n",
      ", {\n",
      "  rose: 2}\n",
      "]\n",
      ", [[a, rose]\n",
      ", {\n",
      "  is: 1  .: 1}\n",
      "]\n",
      ", [[rose, .]\n",
      ", {\n",
      "  ___END__: 1}\n",
      "]\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 231
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After having a good understanding of how Markovify works, let's try to feed the model with more data. In the week3 folder, you can find a txt file containing <i>The Picture of Dorian Gray</i> from Oscar Wilde, downloaded from Project Gutenberg.",
   "id": "773564aa4c2495e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T21:39:06.379731Z",
     "start_time": "2025-11-14T21:39:06.374602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get raw text as string.\n",
    "with open(\"pg26740.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "meta, sep, content = text.partition(\"THE PREFACE\") # using the .partition() method to get rid of text about the book\n",
    "print(meta)"
   ],
   "id": "ebe389efaee2c4e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg eBook of The Picture of Dorian Gray\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n",
      "Title: The Picture of Dorian Gray\n",
      "\n",
      "Author: Oscar Wilde\n",
      "\n",
      "Release date: October 1, 2008 [eBook #26740]\n",
      "                Most recently updated: March 10, 2010\n",
      "\n",
      "Language: English\n",
      "\n",
      "Credits: Produced by David Clarke, Chuck Greif and the Online\n",
      "        Distributed Proofreading Team at http://www.pgdp.net\n",
      "\n",
      "\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK THE PICTURE OF DORIAN GRAY ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by David Clarke, Chuck Greif and the Online\n",
      "Distributed Proofreading Team at http://www.pgdp.net\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE PICTURE OF DORIAN GRAY\n",
      "\n",
      "BY\n",
      "\n",
      "OSCAR WILDE\n",
      "\n",
      "LONDON: SIMPKIN, MARSHALL,\n",
      "\n",
      "HAMILTON, KENT & CO., LTD.\n",
      "\n",
      "PARIS\n",
      "\n",
      "ON SALE AT YE OLD PARIS BOOKE SHOPPE\n",
      "\n",
      "11 RUE DE CHÂTEAUDUN\n",
      "\n",
      "_Registered at Stationers' Hall and protected\n",
      "under the Copyright Law Act.\n",
      "\n",
      "First published in complete book form in 1891 by\n",
      "Messrs. Ward, Lock & Co. (London),\n",
      "\n",
      "First printed in this Edition April 1913,\n",
      "Reprinted June 1913, September 1913,\n",
      "June 1914, January 1916\n",
      "October 1916._\n",
      "\n",
      "_See the Bibliographical Note on certain Pirated and Mutilated\n",
      "Editions of \"Dorian Gray\" at the end of this present volume._\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 407
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T21:39:09.763107Z",
     "start_time": "2025-11-14T21:39:09.653876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build the model.\n",
    "text_model = markovify.Text(content)\n",
    "\n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    print(text_model.make_sentence())"
   ],
   "id": "2ecabec452e937eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was blood on the canvas grinning at the club to look for you, Alan.\n",
      "Why had he not known before, he wondered if he had no curiosity.\n",
      "One could not bear the burden of his face.\n",
      "As for conversation, there are no temptations there.\n",
      "It was conscious that the moonlight in the passage, and the man who had destroyed her life.\n"
     ]
    }
   ],
   "execution_count": 408
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also specify the maximum character length for the generated sentence with `make_short_sentence()`.\n",
   "id": "c5f1fa69022627d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:10:14.236002Z",
     "start_time": "2025-11-14T22:10:14.169128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print three randomly-generated sentences of no more than 20 characters\n",
    "for i in range(3):\n",
    "    print(text_model.make_short_sentence(20, tries=100)) # increase attempt to reduce the chance of None for short sentences"
   ],
   "id": "37f1c66cb10912d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much that is!\n",
      "It had been greeted.\n",
      "I know you are.\n"
     ]
    }
   ],
   "execution_count": 455
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can use this technique to create some rhythm in our generated result.",
   "id": "7aeeb1194db5295a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:10:22.727886Z",
     "start_time": "2025-11-14T22:10:22.684709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Self defined function to make sure a sentence is within a character range between min and max\n",
    "def make_sentence_range(min, max, tries=10):\n",
    "    # using a while loop here to avoid the case of None\n",
    "    sentence = None\n",
    "    for i in range(tries):\n",
    "        sentence = text_model.make_short_sentence(max)\n",
    "        if sentence is not None and len(sentence) > min:\n",
    "            break\n",
    "    return sentence\n",
    "\n",
    "print(text_model.make_short_sentence(30, tries=100))\n",
    "print(make_sentence_range(80, 100))\n",
    "print(text_model.make_short_sentence(20, tries=100))"
   ],
   "id": "3ee00b86dc80f0d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are like red roses.\n",
      "It is all that he had wished to see the world Basil Hallward's disappearance would soon pass away.\n",
      "He began to whimper.\n"
     ]
    }
   ],
   "execution_count": 456
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Markovify assumes us to use text files with normal sentence punctuation by default. If the text file is using line breaks (poems, lyrics, list of words, headlines...) we can use `markovify.NewlineText()` instead.",
   "id": "a87caebee65cf2b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:23:19.831641Z",
     "start_time": "2025-11-14T23:23:19.647102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "# retrieving a txt file from github\n",
    "url = \"https://raw.githubusercontent.com/htuann2712/lyrics_retrieval/refs/heads/main/corpus.txt\"\n",
    "text = requests.get(url).text\n",
    "\n",
    "model = markovify.NewlineText(text, state_size=1)\n",
    "\n",
    "for i in range(4):\n",
    "    print(model.make_short_sentence(70, tries=100))\n"
   ],
   "id": "80c5f82373336885",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I always had that get caught in many professions.\n",
      "Just a reflection of paying back the expectation of days, so grey\n",
      "Just a feeling I've done\n",
      "I'm so grey\n"
     ]
    }
   ],
   "execution_count": 520
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Markovify uses word-level Markov chains by default, but we can modify its behavior to build character-level models instead. Character-level Markov models are especially useful for generating new words or names. In this example, we’ll use a list of color names to train a character-level model and generate new, Markovify-based color names.",
   "id": "6970e52eb903b180"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:48:04.512498Z",
     "start_time": "2025-11-14T22:48:04.507302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We are defining our own class here based on the NewlineText class from markovify\n",
    "class CharacterText(markovify.NewlineText):\n",
    "    # Split text into characters\n",
    "    def word_split(self, sentence):\n",
    "        return list(sentence)\n",
    "\n",
    "    # Join characters back into a string\n",
    "    def word_join(self, words):\n",
    "        return \"\".join(words)\n",
    "\n",
    "text = open(\"100_color_names.txt\").read()\n",
    "\n",
    "# Build the model.\n",
    "model = CharacterText(text, state_size=2)\n",
    "\n",
    "print(\"Generated color names:\")\n",
    "# Generate text\n",
    "for i in range(5):\n",
    "    print(model.make_sentence(tries=100))"
   ],
   "id": "bb97b55042e66b2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated color names:\n",
      "Magentardander\n",
      "Eggplachsia\n",
      "Safoamaroon\n",
      "Sandy\n",
      "Auby\n"
     ]
    }
   ],
   "execution_count": 500
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Combining Two Markov Models\n",
   "id": "7af8be4257555e79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can merge combine two different markov models and mix them in the ratio that you want.",
   "id": "567f17f1767da1e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:03:09.604737Z",
     "start_time": "2025-11-14T22:03:09.309849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model A loads Frankenstein\n",
    "with open(\"pg84.txt\") as f:\n",
    "    text_a = f.read()\n",
    "\n",
    "meta_a, sep_a, content_a = text_a.partition(\"Letter 1\")\n",
    "#print(meta_a)\n",
    "model_a = markovify.Text(content_a, state_size=3)\n",
    "\n",
    "# Model B loads Thus Spake Zarathustra\n",
    "with open(\"pg1998.txt\") as f:\n",
    "    text_b = f.read()\n",
    "\n",
    "meta_b, sep_b, content_b = text_b.partition(\"\\n\\nTHUS SPAKE ZARATHUSTRA.\\n\\n\")\n",
    "# print(meta_b)\n",
    "model_b = markovify.Text(content_b, state_size=3)\n",
    "\n",
    "model_combined = markovify.combine([ model_a, model_b ], [ 1, 1 ])  # merging them with the ratio of 1:1\n"
   ],
   "id": "7ad6764a4263a2b1",
   "outputs": [],
   "execution_count": 453
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can try to generate a paragraph with more consistency by using `make_sentence_with_start()`.",
   "id": "79e2bdbff1583c96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:03:15.277500Z",
     "start_time": "2025-11-14T22:03:15.255606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first = model_combined.make_sentence_with_start(\"I\", tries=100)\n",
    "second = model_combined.make_sentence_with_start(\"Zarathustra\", tries=100)\n",
    "third = model_combined.make_sentence_with_start(\"He\", tries=100)\n",
    "paragraph = first + \" \" + second + \" \" + third\n",
    "\n",
    "print(paragraph)"
   ],
   "id": "7e9e28603f3171b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I know not; despair had not yet taken possession of me; my feelings were altered to those of horror and hatred. Zarathustra himself, however, led the ugliest man the murderer of William, of Justine, and of Clerval. He saw what modern anarchists and revolutionists do NOT see—namely, that man is who believes his native town to be the child-bearer, and endure the pangs of the child-bearer.\n"
     ]
    }
   ],
   "execution_count": 454
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For more detailed documentation, check out [the official GitHub Repository](https://github.com/jsvine/markovify).",
   "id": "aa209dfd4e691c4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 2\n",
    "\n",
    "Find two text files of distinct styles and try to merge them with markovify."
   ],
   "id": "809733477afc4be5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dff24fa76ddf7138"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
